ğŸ” Sure Tomorrow Insurance â€” Machine Learning Evaluation
ğŸ“Œ Project Overview
Sure Tomorrow, an insurance company, is exploring how machine learning can enhance their business. This project investigates the feasibility and effectiveness of ML models in addressing four real-world business challenges:

Find similar customers for targeted marketing.

Classify whether a new customer is likely to receive an insurance benefit.

Predict the number of insurance benefits a customer may receive.

Protect client data through obfuscation without reducing model performance.

ğŸ¯ Project Objectives
Task	Objective
Task 1	Help agents identify similar customers for targeted marketing using similarity metrics.
Task 2	Build a classification model to predict the likelihood of a customer receiving an insurance benefit.
Task 3	Use linear regression to predict the number of benefits a customer may receive.
Task 4	Obfuscate customer data to protect personal information while preserving model performance.

ğŸ“Š Data Preparation
âœ… Cleaning & Preprocessing:
Standardized column names for consistency:

Gender â†’ gender, Age â†’ age, Salary â†’ income, Family members â†’ family_members, Insurance benefits â†’ insurance_benefits

Converted age from float to integer.

Found 153 duplicate rows â€” these may represent unique customers with identical demographics but were retained for modeling.

Created scaled and unscaled versions of the dataset to compare model performance with and without feature scaling.

ğŸ” Task Summaries
ğŸ§­ Task 1: Find Similar Customers
Applied Euclidean and Manhattan distance metrics.

Observations:

Scaled data tends to group customers by number of family members.

Unscaled data emphasizes income, due to its wider range.

Conclusion: Scaling significantly impacts similarity-based groupings and should be considered depending on business priorities.

âœ… Task 2: Classify Insurance Benefit Eligibility
Used K-Nearest Neighbors (KNN) for binary classification.

Evaluation metric: F1 Score (due to class imbalance).

Scaling	Neighbors	F1 Score
Unscaled	1	0.61
Unscaled	10	0.00
Scaled	1	0.97
Scaled	10	0.88

Conclusion: Scaling dramatically improves KNN performance.

ğŸ“ˆ Task 3: Predict Number of Benefits (Regression)
Used Linear Regression to predict insurance_benefits.

Data Version	RMSE	RÂ² Score
Unscaled	0.34	0.66
Scaled	0.34	0.66

Conclusion: Scaling had no impact on linear regression results â€” expected, as linear regression isnâ€™t sensitive to feature scale.

ğŸ” Task 4: Data Obfuscation
Applied a data transformation algorithm to mask personal information.

Re-ran the linear regression model on obfuscated data.

Data Version	RMSE	RÂ² Score
Obfuscated Unscaled	0.34	0.66
Obfuscated Scaled	0.34	0.66

Conclusion: The obfuscation technique did not degrade model performance, proving its effectiveness for privacy-preserving ML.

ğŸ§  Key Learnings
Scaling is essential for distance-based models like KNN or clustering.

Linear models are robust to feature scaling but still benefit from clean, normalized data.

Data obfuscation can be implemented without harming predictive performance, making it viable for real-world privacy needs.

ğŸ§° Technologies Used
Python: pandas, numpy, scikit-learn

ML Algorithms:

KNN (Classification)

Linear Regression (Regression)

Metrics:

F1 Score

RMSE, RÂ²

ğŸ“ Project Structure
bash
Copy
Edit
sure-tomorrow-ml/
â”‚
â”œâ”€â”€ data/                     # Raw and processed datasets
â”œâ”€â”€ notebooks/                # Task-specific notebooks
â”œâ”€â”€ models/                   # Trained models (optional)
â”œâ”€â”€ utils/                    # Data transformation & helper functions
â”œâ”€â”€ README.md                 # Project overview
â””â”€â”€ requirements.txt          # Dependencies
âœ… Conclusion
Machine learning can provide real value to Sure Tomorrow across multiple areas, including:

Customer segmentation

Risk prediction

Forecasting

Privacy-preserving data analysis

The results validate the feasibility of adopting ML-driven solutions in insurance with attention to data preprocessing, model selection, and data security.


